{"val_loss":0.348120593484972,"test_accuracy":0.868,"_wandb":{"runtime":17},"train_loss":0.3204655040789924,"confusion_matrix_table":{"artifact_path":"wandb-client-artifact://v2bikpv671mbv14opfsxz71v3rzvf44dhgbydqz2a4qarc2w1545aka9t7b4sq59eucbzynfmeq5v36ntzqwp0cufw1nd5q1613cux3ug3ejgsx55j9tn8qncl3hv2hb/confusion_matrix_table.table.json","_latest_artifact_path":"wandb-client-artifact://nnfa0uojzp16h6qil12y1bc8rr4rlt1wgozqjmjmqk7tw3kn5gg5tasqtausoe6yi28q9yoag73o776a8pbnmwdbjadkz622zj6o7ghz8luqypsog6uoz1ugu0rmislu:latest/confusion_matrix_table.table.json","path":"media/table/confusion_matrix_table_8_338c97c912189e6ea062.table.json","ncols":3,"nrows":100,"_type":"table-file","sha256":"338c97c912189e6ea0620db706205782b1fab4b1e33013d36878fce87258588b","size":2932},"_step":8,"val_accuracy":0.877,"epoch":5,"_runtime":17.693021053,"epoch_time":3.4981091022491455,"_timestamp":1.7411925393913267e+09,"train_accuracy":0.8819444444444444,"total_training_time":15.198498725891113,"Model Run history":{"train_acc":[0.8037222222222222,0.8556296296296296,0.8687407407407407,0.8778703703703704,0.8819444444444444],"val_loss":[0.48654034559137394,0.35182248661897403,0.3555593401751905,0.3281810155206491,0.348120593484972],"val_acc":[0.8243333333333334,0.8741666666666666,0.8728333333333333,0.8816666666666667,0.877],"train_loss":[0.5578706526860794,0.40044399521710805,0.36035238385189067,0.3365331670225835,0.3204655040789924]}}