{"_step":8,"_timestamp":1.7412422890833893e+09,"val_accuracy":0.873,"train_loss":0.35215289621519663,"total_training_time":14.245139598846436,"val_loss":0.3595200588406661,"epoch_time":2.913775682449341,"confusion_matrix_table":{"sha256":"45836f870e2535545d1b51e847db6b6ceccae351ccf6ab6620c5e36f7df046a9","size":2934,"artifact_path":"wandb-client-artifact://mh2wbuzad8sy8ie7zy8p2e8vce9jnq9shyl80iexqhcnrul9iqar2d9aqgw4vlbgaxlpwtvuc5fahw1587i5yqy9ze5j21q2bjxv7w7ikqz5cjx1sy3avoxwj03mjkhp/confusion_matrix_table.table.json","_latest_artifact_path":"wandb-client-artifact://tak4fjj039m5nbwq0bvj2g42ekun31lhny3fg6nnknw7w00in1fzt0f90plzx08em5z6yep6xqxqer2p9npsgl9xi0bpdbsoos19yrmpw9u1b35jtjjkzd6fia3ti5nj:latest/confusion_matrix_table.table.json","path":"media/table/confusion_matrix_table_8_45836f870e2535545d1b.table.json","ncols":3,"nrows":100,"_type":"table-file"},"Model Run history":{"train_acc":[0.8133518518518519,0.8520185185185185,0.8633148148148149,0.8692037037037037,0.8733148148148148],"val_loss":[0.43364615426268743,0.39725802253249815,0.3933570735226934,0.3908265833797022,0.3595200588406661],"val_acc":[0.8436666666666667,0.8616666666666667,0.8666666666666667,0.8605,0.873],"train_loss":[0.537220393976181,0.41188631489994976,0.3814516445864082,0.36298310638972336,0.35215289621519663]},"_wandb":{"runtime":15},"test_accuracy":0.8641,"_runtime":15.531715425,"train_accuracy":0.8733148148148148,"epoch":5}