{"train_accuracy":0.860462962962963,"_wandb":{"runtime":21},"_runtime":21.89982028,"val_loss":0.42010152998963174,"val_accuracy":0.8505,"test_accuracy":0.8404,"total_training_time":20.67109727859497,"_timestamp":1.7412404397348926e+09,"confusion_matrix_table":{"size":2932,"artifact_path":"wandb-client-artifact://ml7jsryjgiqcqxtczi6obbm7j1evocxj5vs7zq46u3dq10vtqypm5jfwy7ukzmbm5dteiwsr619ya5rudq49xib5mof8bal2tchumwr7n3vdlr2g43cuwp5a8g91d69r/confusion_matrix_table.table.json","_latest_artifact_path":"wandb-client-artifact://8z8q46wrev0m24ddyasuco8cmg87hg52nvibr8ktlgqjsb9b24serpt2aeqrbq6cwzw2q2adgnoi1se55mz300aph4vwduc4js51xt6pzlfvq53bldio72761resp7w8:latest/confusion_matrix_table.table.json","path":"media/table/confusion_matrix_table_13_17caf910a6bc42fef06e.table.json","ncols":3,"nrows":100,"_type":"table-file","sha256":"17caf910a6bc42fef06e92d3546f73ab01aca781231142ec3ced5742c4157ba4"},"train_loss":0.40182484157077947,"_step":13,"Model Run history":{"val_loss":[0.49160920713855777,0.45911463967702554,0.43827859649170653,0.44998444102147034,0.4316098440472801,0.4375856694371128,0.41664466221911645,0.4315038289250282,0.42210320831565773,0.42010152998963174],"val_acc":[0.8305,0.8443333333333334,0.8485,0.8411666666666666,0.847,0.847,0.8525,0.8506666666666667,0.8488333333333333,0.8505],"train_loss":[0.6435967796573264,0.4764817236477017,0.45277908653988724,0.43924793778949384,0.4305903133732814,0.4218538417576223,0.41394126179878976,0.4090616336870463,0.4036362673106732,0.40182484157077947],"train_acc":[0.7795555555555556,0.8353703703703703,0.8433148148148149,0.849037037037037,0.850037037037037,0.8531296296296297,0.8566851851851852,0.8567407407407407,0.8583518518518518,0.860462962962963]},"epoch_time":2.736365795135498,"epoch":10}