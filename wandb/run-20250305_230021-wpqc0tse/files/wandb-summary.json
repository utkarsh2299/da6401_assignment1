{"train_accuracy":0.8840185185185185,"val_loss":0.30991189280746,"confusion_matrix_table":{"nrows":100,"_type":"table-file","sha256":"1e6965771c9188bbc3aa69aa34973a822e948f126011a0ef6622b304f97203be","size":2929,"artifact_path":"wandb-client-artifact://5hx3pok2agkd7l2w6mlnqkggbhwwocu3woxvp7mxygtn2xfv7am5d94vp4j38wiv67843vowhf1n2hsw0vtdxytnj9mpgm6rcnerglue1xr1uzi2skp19uo2iuxhhnsg/confusion_matrix_table.table.json","_latest_artifact_path":"wandb-client-artifact://w9vjklubr38lmnn9y6piaygo1b8em4j2cr43lni09exve6py6fuyz34acbfn57u818ctkxqx4x89ea7zpnok6plciaur0brmjooxadcb1pfz88vhsf1vprapyrq24gn9:latest/confusion_matrix_table.table.json","path":"media/table/confusion_matrix_table_8_1e6965771c9188bbc3aa.table.json","ncols":3},"Model Run history":{"val_acc":[0.8475,0.8571666666666666,0.8616666666666667,0.8848333333333334,0.8908333333333334],"train_loss":[0.4934190967947215,0.38980314970379754,0.3551955728900306,0.3350974881511205,0.3153422684213083],"train_acc":[0.8195185185185185,0.8560555555555556,0.8686666666666667,0.8759444444444444,0.8840185185185185],"val_loss":[0.4197000476849212,0.40438383729314203,0.40027370030138815,0.3304938212307413,0.30991189280746]},"_timestamp":1.7411958869277368e+09,"epoch":5,"val_accuracy":0.8908333333333334,"total_training_time":63.6539740562439,"_step":8,"train_loss":0.3153422684213083,"_wandb":{"runtime":65},"epoch_time":12.458508014678955,"_runtime":65.347084934,"test_accuracy":0.8745}