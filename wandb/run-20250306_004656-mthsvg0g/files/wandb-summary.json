{"val_accuracy":0.8626666666666667,"train_accuracy":0.8811851851851852,"test_accuracy":0.8576,"train_loss":0.32355412649698395,"val_loss":0.3618583837111908,"confusion_matrix_table":{"_type":"table-file","sha256":"d99b1d763ed19046afd78418b94d5cf1091a57c624dc212921075366c7c10fa6","size":2931,"artifact_path":"wandb-client-artifact://slm3l8nddpyktf9a08ggnjxet4p5kd2186gpjygfv16ihq6nbcwa584fkevoz8b1ojifph6vmd2gpmh8hyd34uh49w1pkck6nrbl1ieomaunxc8tvowh6yeevpnb5527/confusion_matrix_table.table.json","_latest_artifact_path":"wandb-client-artifact://tkq11rb91wpebp2i0ogh3lnom27gyqd6o1s9jitg19kdyvky9bow188gdv4i8lb91artkelsoqceta2rd1973wzr3glb9xnfnra3dyrq9nw89jm4zdvmafknccfgsiuj:latest/confusion_matrix_table.table.json","path":"media/table/confusion_matrix_table_8_d99b1d763ed19046afd7.table.json","ncols":3,"nrows":100},"total_training_time":44.7147901058197,"Model Run history":{"val_acc":[0.861,0.8716666666666667,0.8666666666666667,0.8731666666666666,0.8626666666666667],"train_loss":[0.47095216463566497,0.37621881125755896,0.3472362751590029,0.33379324980661973,0.32355412649698395],"train_acc":[0.8331296296296297,0.8636666666666667,0.8745555555555555,0.8776851851851852,0.8811851851851852],"val_loss":[0.3842527421781811,0.3483458934833241,0.35604049473313776,0.33629630318189885,0.3618583837111908]},"_runtime":45.794977197,"epoch_time":8.029584884643555,"epoch":5,"_step":8,"_wandb":{"runtime":45},"_timestamp":1.7412022621770616e+09}