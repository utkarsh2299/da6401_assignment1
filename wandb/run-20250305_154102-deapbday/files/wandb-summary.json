{"val_loss":2.300532655107293,"confusion_matrix_table":{"path":"media/table/confusion_matrix_table_5_2aa1746aea4c9d674191.table.json","ncols":3,"nrows":100,"_type":"table-file","sha256":"2aa1746aea4c9d6741911ebdf53dc4b1eb18191bb1718a4ce314542f33ca324f","size":2919,"artifact_path":"wandb-client-artifact://lviaky93cbyossf6vsxdfsjyjjk4rjpfu7yp85c80vzj6tys18x319sceb3oydk4mz3wi4gd9d9rkdqvieg3z3ex821rv47lklwmuye56heml7m7vo5hjog70zvrqid2/confusion_matrix_table.table.json","_latest_artifact_path":"wandb-client-artifact://uvb3q04eh7ei13wfepkua97a3tdejjlsful2449tbzfu8kjzp7e42bzzv5swvsq4iz63ttusfu98z6oev37vl31scq4npn5w6d146t7zgnbcqmxf6f19z1eyo54ln1zu:latest/confusion_matrix_table.table.json"},"train_loss":2.6299724365285484,"_timestamp":1.7411694854622324e+09,"Model Run history":{"val_loss":[2.304673906236682,2.300532655107293],"val_acc":[0.097,0.1085],"train_loss":[2.383593980997831,2.6299724365285484],"train_acc":[0.10394444444444445,0.12431481481481481]},"val_accuracy":0.1085,"_step":5,"test_accuracy":0.1125,"epoch_time":10.626219987869263,"epoch":2,"train_accuracy":0.12431481481481481,"_wandb":{"runtime":22},"_runtime":22.469368672,"total_training_time":21.183783292770386}