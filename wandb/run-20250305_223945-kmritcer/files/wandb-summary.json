{"val_accuracy":0.8695,"val_loss":0.3607781809190921,"_wandb":{"runtime":75},"_step":8,"epoch_time":15.101241111755371,"train_accuracy":0.8819444444444444,"_timestamp":1.741194661355394e+09,"confusion_matrix_table":{"size":2929,"artifact_path":"wandb-client-artifact://roqu4n6v3fe728tbzc0gmain9ir5kif8olw7y9w9pjct1yj2trnji3eqfnyjuhr8umwr0rbuneke1neb1736xyofq5dbgblt2vjxdpqpcmurz4krkul78mkmlv1mdj4n/confusion_matrix_table.table.json","_latest_artifact_path":"wandb-client-artifact://o1s8qatndzytx4d428f6tmakiemfxkj3jrtu6k9ileo0jotmrb30ptq42mmrmoc4p16xb9ctskc6tmxb99ecn6q0tpesr0skhtklkj73af756fvyln5wgxtep1r1zj74:latest/confusion_matrix_table.table.json","path":"media/table/confusion_matrix_table_8_8e88562593251b82a37a.table.json","ncols":3,"nrows":100,"_type":"table-file","sha256":"8e88562593251b82a37a83284f1bc0abda1d6628d96cffd9f8b0dc7c20fdecfc"},"train_loss":0.3495234267940535,"_runtime":75.73034732,"epoch":5,"test_accuracy":0.8539,"total_training_time":73.87194466590881,"Model Run history":{"val_loss":[0.42060952486305875,0.4033174738002272,0.3753082968445639,0.3610064578358339,0.3607781809190921],"val_acc":[0.8526666666666667,0.8525,0.8683333333333333,0.872,0.8695],"train_loss":[0.5335257377575061,0.42183004640392224,0.3888587191670957,0.365268505379133,0.3495234267940535],"train_acc":[0.819037037037037,0.8575925925925926,0.8689259259259259,0.8765,0.8819444444444444]}}