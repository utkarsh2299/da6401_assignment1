{"val_loss":0.6194819796594849,"_step":8,"confusion_matrix_table":{"_type":"table-file","sha256":"10f4b7690a3133f5a1ba0b913d676d244e13f220bcb0127d15a1b7f72569d38e","size":2928,"artifact_path":"wandb-client-artifact://1h0ajeu9c1l7sci7z4ittq4qscl9x2h1m56z5b9as5pz77ya9wju6ufha63495kyl2dot41tiodn5j6eol1zd5hio99g7w5ukmk5uoi6zr013v1e11f4rpzkgoriwu0p/confusion_matrix_table.table.json","_latest_artifact_path":"wandb-client-artifact://ggwbq53pca63vzc23dq6e12nroe0x571dtvpo60u6gquf6dy9akhu8zvctnp4s8u2djpchbwo85mv5f3hyfxcppaicmi6ec04keo6xzgnm4u9wf54zrsx81yhdgp8ymh:latest/confusion_matrix_table.table.json","path":"media/table/confusion_matrix_table_8_10f4b7690a3133f5a1ba.table.json","ncols":3,"nrows":100},"epoch_time":23.1510910987854,"Model Run history":{"val_acc":[0.44,0.6386666666666667,0.722,0.7278333333333333,0.7391666666666666],"train_loss":[1.61844057960354,1.0740275277929634,0.7839511053674442,0.6573981958211861,0.6161413639393113],"train_acc":[0.2803333333333333,0.5295555555555556,0.7060925925925926,0.7313518518518518,0.7421851851851852],"val_loss":[1.2339451807430277,0.9324015686440804,0.7023314821175166,0.6599520595850017,0.6194819796594849]},"_wandb":{"runtime":110},"test_accuracy":0.7356,"train_loss":0.6161413639393113,"_timestamp":1.7411664570122118e+09,"train_accuracy":0.7421851851851852,"val_accuracy":0.7391666666666666,"epoch":5,"total_training_time":108.3857626914978,"_runtime":110.267489319}