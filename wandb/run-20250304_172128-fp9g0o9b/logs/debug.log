2025-03-04 17:21:28,841 INFO    Thread-2  :1428444 [wandb_setup.py:_flush():68] Current SDK version is 0.19.2
2025-03-04 17:21:28,842 INFO    Thread-2  :1428444 [wandb_setup.py:_flush():68] Configure stats pid to 1428444
2025-03-04 17:21:28,842 INFO    Thread-2  :1428444 [wandb_setup.py:_flush():68] Loading settings from /speech/utkarsh/.config/wandb/settings
2025-03-04 17:21:28,842 INFO    Thread-2  :1428444 [wandb_setup.py:_flush():68] Loading settings from /speech/utkarsh/da6401_assignment1/wandb/settings
2025-03-04 17:21:28,842 INFO    Thread-2  :1428444 [wandb_setup.py:_flush():68] Loading settings from environment variables
2025-03-04 17:21:28,842 INFO    Thread-2  :1428444 [wandb_init.py:_log_setup():523] Logging user logs to /speech/utkarsh/da6401_assignment1/wandb/run-20250304_172128-fp9g0o9b/logs/debug.log
2025-03-04 17:21:28,842 INFO    Thread-2  :1428444 [wandb_init.py:_log_setup():524] Logging internal logs to /speech/utkarsh/da6401_assignment1/wandb/run-20250304_172128-fp9g0o9b/logs/debug-internal.log
2025-03-04 17:21:28,842 INFO    Thread-2  :1428444 [wandb_init.py:init():641] calling init triggers
2025-03-04 17:21:28,842 INFO    Thread-2  :1428444 [wandb_init.py:init():647] wandb.init called with sweep_config: {'activation': 'sigmoid', 'batch_size': 32, 'epochs': 2, 'hidden_layer_size': 64, 'hidden_layers_count': 5, 'learning_rate': 0.0001, 'optimizer': 'momentum', 'weight_decay': 0.0001, 'weight_init': 'random'}
config: {}
2025-03-04 17:21:28,842 INFO    Thread-2  :1428444 [wandb_init.py:init():674] starting backend
2025-03-04 17:21:29,708 INFO    Thread-2  :1428444 [wandb_init.py:init():678] sending inform_init request
2025-03-04 17:21:29,940 INFO    Thread-2  :1428444 [backend.py:_multiprocessing_setup():104] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-03-04 17:21:29,976 INFO    Thread-2  :1428444 [wandb_init.py:init():693] backend started and connected
2025-03-04 17:21:29,976 INFO    Thread-2  :1428444 [wandb_run.py:_config_callback():1283] config_cb None None {'activation': 'sigmoid', 'batch_size': 32, 'epochs': 2, 'hidden_layer_size': 64, 'hidden_layers_count': 5, 'learning_rate': 0.0001, 'optimizer': 'momentum', 'weight_decay': 0.0001, 'weight_init': 'random'}
2025-03-04 17:21:29,985 INFO    Thread-2  :1428444 [wandb_init.py:init():786] updated telemetry
2025-03-04 17:21:30,019 INFO    Thread-2  :1428444 [wandb_init.py:init():818] communicating run to backend with 90.0 second timeout
2025-03-04 17:21:30,783 INFO    Thread-2  :1428444 [wandb_init.py:init():868] starting run threads in backend
2025-03-04 17:21:32,493 INFO    Thread-2  :1428444 [wandb_run.py:_console_start():2415] atexit reg
2025-03-04 17:21:32,493 INFO    Thread-2  :1428444 [wandb_run.py:_redirect():2265] redirect: wrap_raw
2025-03-04 17:21:32,494 INFO    Thread-2  :1428444 [wandb_run.py:_redirect():2330] Wrapping output streams.
2025-03-04 17:21:32,494 INFO    Thread-2  :1428444 [wandb_run.py:_redirect():2355] Redirects installed.
2025-03-04 17:21:32,507 INFO    Thread-2  :1428444 [wandb_init.py:init():910] run started, returning control to user process
2025-03-04 17:21:51,954 WARNING MsgRouterThr:1428444 [router.py:message_loop():75] message_loop has been closed
2025-03-04 17:21:52,141 INFO    Thread-2  :1428444 [wandb_run.py:_finish():2140] finishing run da24s011-indian-institute-of-technology-madras/fashion-mnist-hyperparameter-sweep/fp9g0o9b
2025-03-04 17:21:52,141 INFO    Thread-2  :1428444 [wandb_run.py:_finish():2140] finishing run da24s011-indian-institute-of-technology-madras/fashion-mnist-hyperparameter-sweep/fp9g0o9b
