{"epoch":5,"confusion_matrix_table":{"ncols":3,"nrows":100,"_type":"table-file","sha256":"5a1bbadbaf65b5757514e9ef47fc2dc4c35efb48f98367a52f1f381b0d116231","size":1801,"artifact_path":"wandb-client-artifact://v5p20u3m3731qu1m4molss6amq1d7956qacp3v38bcjaqasl3vjbkfnne0w9ufe3mvlddo1h4tomp7f93jb4ln04pgf4in3wuqb3fb3iyzhsrjsvem4pmh1ry2kpynkq/confusion_matrix_table.table.json","_latest_artifact_path":"wandb-client-artifact://yqc70qpxvytp1vor7xuu7hd38mmb85lq9iw5uus8p0xk5h3ngrg91uc0vdtgaarbgay37kbb7kslllicgsi1ewl711vc7qgbcwzerfj383i5d54f70u3eozrisfb2znl:latest/confusion_matrix_table.table.json","path":"media/table/confusion_matrix_table_8_5a1bbadbaf65b5757514.table.json"},"val_loss":0.1958073063184434,"Model Run history":{"train_loss":[0.3513205174832506,0.23884301751005435,0.22433883018326492,0.21348481585323467,0.20783002850400562],"train_acc":[0.9010370370370371,0.9339259259259259,0.9397222222222222,0.9424814814814815,0.9446481481481481],"val_loss":[0.24083831051096358,0.21130508223317562,0.261487882755907,0.201481431195967,0.1958073063184434],"val_acc":[0.9296666666666666,0.939,0.9223333333333333,0.9438333333333333,0.942]},"train_accuracy":0.9446481481481481,"val_accuracy":0.942,"_runtime":8.244124747,"_timestamp":1.7422141812004786e+09,"_wandb":{"runtime":8},"_step":8,"epoch_time":1.4682393074035645,"total_training_time":7.207944631576538,"train_loss":0.20783002850400562,"test_accuracy":0.9472}