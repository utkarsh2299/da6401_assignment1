{"train_accuracy":0.863574074074074,"val_accuracy":0.8585,"train_loss":0.3722577400944305,"test_accuracy":0.8528,"_timestamp":1.741204384786527e+09,"total_training_time":6.22600245475769,"confusion_matrix_table":{"nrows":100,"_type":"table-file","sha256":"3d710a20aa641001638bae6ac4d2706fc849b506a9bb16fdb30e979ab8b01daf","size":2931,"artifact_path":"wandb-client-artifact://ru79ytzb50v6w94tsb1kjrn5nsw2hzotdo2y22jkbmv1xgiz4g2g5y58axhyjdt1k0okf84bon8vam918rf92kipo4u22yj06dryri48hfosxwcf1ln06barezyypw0p/confusion_matrix_table.table.json","_latest_artifact_path":"wandb-client-artifact://ororgm9r9tdsa2ahc9rx6k8fje8i7kd9q6kspj4qfulnpeqzaid2g7gfs6jblqfrpfdp3nccboifvgyc7cjv5sojr99az4t9awv7i45p7mgg4ml5pfdfgtsohcbzxnpy:latest/confusion_matrix_table.table.json","path":"media/table/confusion_matrix_table_8_3d710a20aa641001638b.table.json","ncols":3},"epoch_time":0.9339780807495117,"_runtime":7.344955339,"_step":8,"epoch":5,"Model Run history":{"val_acc":[0.825,0.85,0.8561666666666666,0.8391666666666666,0.8585],"train_loss":[0.6447738567904926,0.4497342335574529,0.4133674793500234,0.3883006131412155,0.3722577400944305],"train_acc":[0.7691851851851852,0.8390185185185185,0.8503888888888889,0.8578703703703704,0.863574074074074],"val_loss":[0.47128652414091116,0.413847578428339,0.4029737705895295,0.42306862329104045,0.3881785904028575]},"val_loss":0.3881785904028575,"_wandb":{"runtime":7}}