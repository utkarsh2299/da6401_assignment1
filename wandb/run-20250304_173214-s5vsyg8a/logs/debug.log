2025-03-04 17:32:14,974 INFO    Thread-2  :1510748 [wandb_setup.py:_flush():68] Current SDK version is 0.19.2
2025-03-04 17:32:14,974 INFO    Thread-2  :1510748 [wandb_setup.py:_flush():68] Configure stats pid to 1510748
2025-03-04 17:32:14,974 INFO    Thread-2  :1510748 [wandb_setup.py:_flush():68] Loading settings from /speech/utkarsh/.config/wandb/settings
2025-03-04 17:32:14,974 INFO    Thread-2  :1510748 [wandb_setup.py:_flush():68] Loading settings from /speech/utkarsh/da6401_assignment1/wandb/settings
2025-03-04 17:32:14,974 INFO    Thread-2  :1510748 [wandb_setup.py:_flush():68] Loading settings from environment variables
2025-03-04 17:32:14,974 INFO    Thread-2  :1510748 [wandb_init.py:_log_setup():523] Logging user logs to /speech/utkarsh/da6401_assignment1/wandb/run-20250304_173214-s5vsyg8a/logs/debug.log
2025-03-04 17:32:14,974 INFO    Thread-2  :1510748 [wandb_init.py:_log_setup():524] Logging internal logs to /speech/utkarsh/da6401_assignment1/wandb/run-20250304_173214-s5vsyg8a/logs/debug-internal.log
2025-03-04 17:32:14,974 INFO    Thread-2  :1510748 [wandb_init.py:init():641] calling init triggers
2025-03-04 17:32:14,974 INFO    Thread-2  :1510748 [wandb_init.py:init():647] wandb.init called with sweep_config: {'activation': 'tanh', 'batch_size': 32, 'epochs': 2, 'hidden_layer_size': 64, 'hidden_layers_count': 4, 'learning_rate': 0.0001, 'optimizer': 'rmsprop', 'weight_decay': 0, 'weight_init': 'xavier'}
config: {}
2025-03-04 17:32:14,974 INFO    Thread-2  :1510748 [wandb_init.py:init():674] starting backend
2025-03-04 17:32:15,584 INFO    Thread-2  :1510748 [wandb_init.py:init():678] sending inform_init request
2025-03-04 17:32:15,673 INFO    Thread-2  :1510748 [backend.py:_multiprocessing_setup():104] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-03-04 17:32:15,707 INFO    Thread-2  :1510748 [wandb_init.py:init():693] backend started and connected
2025-03-04 17:32:15,708 INFO    Thread-2  :1510748 [wandb_run.py:_config_callback():1283] config_cb None None {'activation': 'tanh', 'batch_size': 32, 'epochs': 2, 'hidden_layer_size': 64, 'hidden_layers_count': 4, 'learning_rate': 0.0001, 'optimizer': 'rmsprop', 'weight_decay': 0, 'weight_init': 'xavier'}
2025-03-04 17:32:15,723 INFO    Thread-2  :1510748 [wandb_init.py:init():786] updated telemetry
2025-03-04 17:32:15,875 INFO    Thread-2  :1510748 [wandb_init.py:init():818] communicating run to backend with 90.0 second timeout
2025-03-04 17:32:16,976 INFO    Thread-2  :1510748 [wandb_init.py:init():868] starting run threads in backend
2025-03-04 17:32:20,427 INFO    Thread-2  :1510748 [wandb_run.py:_console_start():2415] atexit reg
2025-03-04 17:32:20,428 INFO    Thread-2  :1510748 [wandb_run.py:_redirect():2265] redirect: wrap_raw
2025-03-04 17:32:20,428 INFO    Thread-2  :1510748 [wandb_run.py:_redirect():2330] Wrapping output streams.
2025-03-04 17:32:20,428 INFO    Thread-2  :1510748 [wandb_run.py:_redirect():2355] Redirects installed.
2025-03-04 17:32:20,430 INFO    Thread-2  :1510748 [wandb_init.py:init():910] run started, returning control to user process
2025-03-04 17:36:52,516 WARNING MsgRouterThr:1510748 [router.py:message_loop():75] message_loop has been closed
2025-03-04 17:36:52,586 INFO    Thread-2  :1510748 [wandb_run.py:_finish():2140] finishing run da24s011-indian-institute-of-technology-madras/fashion-mnist-hyperparameter-sweep/s5vsyg8a
2025-03-04 17:36:52,587 INFO    Thread-2  :1510748 [wandb_run.py:_finish():2140] finishing run da24s011-indian-institute-of-technology-madras/fashion-mnist-hyperparameter-sweep/s5vsyg8a
