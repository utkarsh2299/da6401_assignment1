{"epoch_time":2.354567050933838,"_timestamp":1.7412018841844816e+09,"_step":8,"train_loss":0.3355452864095825,"confusion_matrix_table":{"path":"media/table/confusion_matrix_table_8_91c698064bc23c7c5fe3.table.json","ncols":3,"nrows":100,"_type":"table-file","sha256":"91c698064bc23c7c5fe361e00340fe724e5bcaface4af09ec59038c2688b744c","size":2932,"artifact_path":"wandb-client-artifact://4kbdpap1k8xg5wm3xno6kzzkbd7obewh44zeeb3f9blo1hp0jcvp3rwxwixt1et6gxq0m0ofqiv5lzqsyzg5wx5flxlkns4kym2lh8pvo2jqap396uftq0kuzwgkflvg/confusion_matrix_table.table.json","_latest_artifact_path":"wandb-client-artifact://gf65ogzoh9uf4lp9968ohopy0vgfejtt3tuj8uv4jx8xxogsb4jr9elldw4juou50dwttdabq8l1hayntnavx8kvs2avddwkzb9pz5hyw0ou77lhpz0g0ot3ua5hurrh:latest/confusion_matrix_table.table.json"},"_runtime":14.242717432,"epoch":5,"Model Run history":{"val_loss":[0.4383948067956239,0.4214803421965574,0.37301293545484465,0.36582009610069205,0.3524176694312344],"val_acc":[0.8438333333333333,0.8426666666666667,0.8648333333333333,0.8648333333333333,0.8711666666666666],"train_loss":[0.5558606382496952,0.4058839692480897,0.37067308905888685,0.3514614169295016,0.3355452864095825],"train_acc":[0.8030555555555555,0.8551666666666666,0.8654259259259259,0.8719629629629629,0.8765]},"train_accuracy":0.8765,"total_training_time":13.223268747329712,"test_accuracy":0.865,"_wandb":{"runtime":14},"val_loss":0.3524176694312344,"val_accuracy":0.8711666666666666}